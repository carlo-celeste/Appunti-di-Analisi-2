\documentclass[11pt,a4paper]{report}

% ============================================================================
% PACCHETTI
% ============================================================================
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{array}
\usepackage{colortbl}
\usepackage{float}
\usepackage{mdframed}
\usepackage{enumitem}
\usepackage{cancel}
\usepackage[hidelinks]{hyperref}
\usepackage{titlesec}
\usepackage{tikz}
\usepackage{tcolorbox}
\tcbuselibrary{skins,breakable}
\usetikzlibrary{patterns,shadings}

% ============================================================================
% IMPOSTAZIONI PAGINA
% ============================================================================
\geometry{
    top=2cm,
    bottom=2cm,
    left=2.5cm,
    right=2.5cm,
    headheight=1cm
}

% Header personalizzato
\pagestyle{fancy}
\fancyhf{}
\lhead{Carlo Celeste}
\chead{Analisi II: Funzioni di più variabili}
\rhead{\thepage}
\renewcommand{\headrulewidth}{0.5pt}

\setlength{\parindent}{0pt}

% ============================================================================
% COLORI PERSONALIZZATI
% ============================================================================
\definecolor{defcolor}{RGB}{0,102,204}      % Blu per definizioni
\definecolor{thmcolor}{RGB}{204,0,102}      % Magenta per teoremi
\definecolor{notecolor}{RGB}{255,235,205}   % Arancione chiaro per note
\definecolor{tableheader}{RGB}{204,0,102}   % Magenta per header tabelle

% ============================================================================
% FORMATTAZIONE CAPITOLI
% ============================================================================
\titleformat{\chapter}[hang]
    {\normalfont\huge\bfseries}
    {}
    {0pt}
    {\Huge}

% ============================================================================
% LOCALIZZAZIONE ITALIANA
% ============================================================================
\renewcommand{\contentsname}{Indice}

% ============================================================================
% AMBIENTI TEOREMATICI
% ============================================================================
% Stile per definizioni
\newtheoremstyle{defstyle}
    {10pt}                          % Spazio sopra
    {10pt}                          % Spazio sotto
    {\itshape}                      % Font del corpo
    {}                              % Indentazione
    {\bfseries\color{defcolor}}     % Font intestazione
    {.}                             % Punteggiatura dopo intestazione
    { }                             % Spazio dopo intestazione
    {}                              % Specifica intestazione

\theoremstyle{defstyle}
\newtheorem{definizione}{Definizione}[section]

% Stile per teoremi
\newtheoremstyle{thmstyle}
    {10pt}
    {10pt}
    {\itshape}
    {}
    {\bfseries\color{thmcolor}}
    {.}
    { }
    {}

\theoremstyle{thmstyle}
\newtheorem{teorema}{Teorema}[section]
\newtheorem{proposizione}{Proposizione}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollario}{Corollario}[section]

% Stile per osservazioni
\theoremstyle{remark}
\newtheorem*{osservazione}{Osservazione}
\newtheorem*{esempio}{Esempio}

% ============================================================================
% AMBIENTI PERSONALIZZATI PER STUDIO
% ============================================================================

% Spazio per note personali
\newcommand{\spazioscritti}[1][4cm]{%
    \vspace{0.5cm}
    \begin{mdframed}[
        backgroundcolor=notecolor,
        linecolor=orange,
        linewidth=1.5pt,
        roundcorner=5pt,
        innertopmargin=10pt,
        innerbottommargin=10pt,
        innerleftmargin=10pt,
        innerrightmargin=10pt
    ]
    {\large\textbf{Spazio per note:}}
    \vspace{#1}
    \end{mdframed}
    \vspace{0.5cm}
}

% ============================================================================
% COMANDI UTILI
% ============================================================================

% Separatore visivo tra sezioni
\newcommand{\separatore}{%
    \vspace{0.8cm}
    \rule{\textwidth}{1pt}
    \vspace{0.8cm}
}

% Mathbf revisionato
\renewcommand{\mathbf}[1]{\underline{\boldsymbol{#1}}}

% ============================================================================
% NOTAZIONE DEL GRADIENTE
% ============================================================================
\let\oldnabla\nabla
\renewcommand{\nabla}{\oldnabla\mkern-3mu}

% ============================================================================
% INIZIO DOCUMENTO
% ============================================================================
\begin{document}

% Pagina del titolo
\begin{center}
    \vspace*{2cm}
    {\Huge\bfseries Corso di Analisi 2\\[0.3cm] Domande e risposte al macro-argomento:\\[0.3cm] EQUAZIONI DIFFERENZIALI}\\[1cm]
    {\large Ultima modifica: \today}\\[0.5cm]
    \vspace{2cm}
\end{center}

\newpage

% Indice
\tableofcontents

\newpage

% ============================================================================
% CONTENUTO DEL DOCUMENTO
% ============================================================================

\chapter{Equazioni Differenziali}
\section{Introduzione alle EDO}
\textbf{1. Cosa si intende per {\color{red}Equazione Differenziale} e cosa la distingue da una normale equazione algebrica?}

\begin{definizione}[Equazione Differenziale]
Un'equazione la cui incognita è una funzione del tipo $y=y(x)$ e in cui sono presenti una o più derivate della stessa funzione incognita.
\end{definizione}
Ovviamente, quando si definisce un'equazione differenziale si sottointende che l'incognita $y=y(x)$, dipende dalla variabile $x \in I \subseteq \mathbb{R}$.

\textbf{2. Qual è la differenza tra {\color{red}un'equazione differenziale ordinaria} e un'equazione delle derivate parziali e cosa si intende con precisione per EDO di ordine n?}

Le equazioni differenziali si dividono in due categorie: EDO (ordinarie), ossia un'equazione differenziale su una funzione di una sola variabile indipendente, e EDP (parziali), ossia un'equazione differenziale su una funzione di più variabile indipendenti. 

\begin{definizione}[Ordine di una EDO] E' l'ordine massimo di derivazione che compare nell'equazione differenziale.
\end{definizione}

\begin{definizione}[EDO di ordine n]
Un'equazione differenziale ordinaria di ordine n ha una sola variabile indipendente e si può scrivere in due forme
\begin{itemize}
    \item Implicita: $F(x, y(x), y'(x), y''(x),...,y^n(x)) = 0$\\
    dove  $y: I \subseteq \mathbb{R} \to \mathbb{R}$ è una funzione reale di variabile reale derivabile $n$ volte in un intervallo $I$\\
    dove $F$ è una funzione tale che $F: U \subseteq \mathbb{R}^{n+2} \to \mathbb{R}$\\
    Quindi, $F$ prende in input $n + 2$ (i due elementi sarebbero x e y(x)) numeri reali provenienti da $U$ e produce in output un singolo numero reale

    \item Esplicita o Forma normale: $y^n(x) = F(x, y(x), y'(x), y''(x),...,y^{n-1}(x))$\\
    dove $y: I \subseteq \mathbb{R}^n \to \mathbb{R}$ e $y^n$ è la derivata di ordine più alto
\end{itemize}
\end{definizione}

\textbf{3. Cosa significa che una funzione è {\color{red}soluzione di un'EDO }su un intervallo I?}

\begin{definizione}[Soluzione di una EDO]
Sia   $F(x, y, y', y'',..y^n) = 0$ con $x \in  I \subseteq \mathbb{R}$ una EDO di ordine n su I.

La sua soluzione è una funzione $\phi = \phi (x)$ definita su (almeno) $I = [a, b] \subseteq \mathbb{R}$ e differenziabile\footnote{Si intende che $\phi$ ammette derivate successive fino all'ordine $n$ in ogni punto dell'intervallo I. In termini di spazi funzionali, ciò equivale a dire che $\phi \in C^n(I)$} $n$ volte su $I$ per cui vale
$F(x, \phi (x), \phi ' (x), \phi ''(x),...,\phi^n (x)) = 0$
\end{definizione}

Il grafico di una singola soluzione nel piano $(x,y)$, definita su un intervallo $I$ è detto curva integrale.

Poiché la soluzione generale è una famiglia di funzioni che contiene le soluzioni della EDO essa dipende da una o più costanti arbitrarie e l'insieme di tutte le soluzioni della EDO è una famiglia di curve integrali.

\textbf{4. Cosa rappresenta {\color{red}l'integrale generale} di un'EDO di ordine n?}
\begin{definizione}[Integrale generale]
E' l'insieme di tutte le soluzioni di una EDO su un intervallo $I$.
\end{definizione}
Quando risolvo un'equazione differenziale cerco tutte le possibili funzioni $y(x)$ che soddisfano l'uguaglianza tra la funzione incognita e le sue derivate.

Per definire in modo migliore il concetto, posso ri-collegarmi alla definizione di primitiva di $f(x)$ dell'Analisi 1: 

Sia $f : (a, b) \to \mathbb{R}$. La funzione $y(x)$ è una primitiva di $f$ in $(a, b)$ se è derivabile in $(a, b)$ e se:
\[
y'(x) = f(x) \quad \forall x \in (a, b)
\]

L'equazione $y'(x) = f(x)$ non è altro che una EDO di primo ordine e la funzione $y(x)$ che soddisfa questa uguaglianza è la soluzione dell'equazione.

Quindi, si può immaginare questa definizione come un test di identità:
\begin{enumerate}
    \item Hai una funzione di partenza $f(x)$.
    \item Cerchi una funzione $y(x)$ tale che, una volta derivata, restituisca esattamente $f(x)$.
    \item Il test: Calcoli la derivata $y'(x)$. Se il risultato è identico a $f(x)$, allora $y(x)$ è una primitiva (ovvero una soluzione della EDO).
\end{enumerate}

Geometricamente, l'integrale generale rappresenta una famiglia di curve:
\[
y(x, c) = \int f(x) \, dx + c
\]
Ogni valore della costante $c \in \mathbb{R}$ identifica una specifica curva nel piano che ha la pendenza data da $f(x)$.

L'integrale generale di una EDO è una famiglia di funzioni che contiene tutte le soluzione della EDO, dipendenti da una variabile indipendente e una costante, ed è prioriamente denotato con $y(x,c)$ perché rappresenta le infinite soluzioni (per il valore c).

\section{EDO lineare}
\textbf{5. Cosa si intende con {\color{red}un'EDO lineare}, ossia cosa significa "lineare" in questo contesto?}\\
Una EDO è lineare se 
\begin{itemize}
    \item $y(x)$ e le sue derivate compaiono solo al primo grado e non dentro funzioni "complesse", come potenze, seno o coseno etc;
    \item $y(x)$ e le sue derivate non sono moltiplicate tra loro;
    \item i coefficenti $a$ dipendono da $x$ e non dalla funzione $y(x)$.
\end{itemize}

\begin{definizione}[Linearità]
Dato $I \subseteq \mathbb{R}$ e sia $L$ un operatore differenziale. Una EDO in forma normale $y^n = F(x, y, y', y'',...,y^{n-1})$ è definita lineare perché esiste un'applicazione lineare fra spazi di due funzioni, ossia $L: C^n (I) \to C^0(I)$, che associa ad ogni funzione $\phi \in C^n(I)$ una funzione continua del tipo:
$L(\phi(x)):= a_n\phi^n(x)+a_{n-1}\phi^{n-1}(x)+...+a_1\phi'(x)+a_0\phi(x)$
\end{definizione}

Bisogna dire che l'applicazione lineare $L$ è una somma di funzione continue ed è lineare in quanto soddisfa la proprietà di additività:
\begin{center}
    $\alpha(L\phi_1(x)) + \beta(L\phi_2(x)) = L(\alpha\phi_1(x) + \beta\phi_2(x))$ 
\end{center}
Con $\alpha,\beta \in \mathbb{R}$ e $\phi_1,\phi_2 \in C^n(I)$

In parole povere, questo significa che non si creano relazioni strane tra le funzioni ed esse sono trattate in modo indipendente (l'operatore L le elabora separatemente e ne somma i risultati) e proporzionale (per esempio, se raddoppi la funzione in ingresso, la funzione in uscita raddoppia ugualmente).


\textbf{6. Cosa si intende con {\color{red}un'EDO lineare di ordine n}?}
\begin{definizione}[EDO Lineare Completa]
Sia il termine noto diverso da 0, essa può essere scritta in due forme
\begin{itemize}
    \item Implicita: $a_ny^n(x)+a_{n-1}y^{n-1}(x)+...+a_1y'(x)+a_0y(x)=f(x)$
    \item Esplicita o forma normale: $y^n(x)+a_{n-1}y^{n-1}(x)+...+a_1y'(x)+a_0y(x)=f(x)$
\end{itemize}
\end{definizione}

\begin{definizione}[EDO Lineare Omogenea associata ad una EDO completa]
Sia il termine noto zero, allora essa si scrive: 
\begin{center}
    $a_ny^n(x)+a_{n-1}y^{n-1}(x)+...+a_1y'(x)+a_0y(x)=0$
\end{center}
\end{definizione}

\section{EDO di I Ordine}
\textbf{6. Cosa si intende con {\color{red}un'EDO lineare di primo ordine} e perché è importante richiedere che a(x) e f(x) siano continue sull'intervallo?}
\begin{definizione}[EDO lineare di primo ordine]
Partendo dalla forma implicita ($F(x, y(x), y'(x)) = 0$) e dalla forma normale ($y'(x) = F(x,y(x)$) di una EDO (non lineare) di primo ordine posso definire due forme per le EDO lineari di primo ordine.

\begin{itemize}
    \item Forma normale: $y'(x) + a(x)y(x) = f(x)$
    \item Omogena associata: $y'(x) + a(x)y(x) = 0$
\end{itemize}
\end{definizione}

Con $x \in [a,b]$ e $a(x), f(x)$ continue in $[a,b]$ perché garantiscono esistenza e unicità della soluzione del problema di Cauchy.

Consideriamo il problema di Cauchy:
\[
\begin{cases} 
y' = f(x, y) \\ 
y(x_0) = y_0 
\end{cases}
\]

La soluzione esiste ed è unica (localmente) se vengono soddisfatte le seguenti condizioni:
\begin{enumerate}
    \item \textbf{Continuità:} $f(x,y)$ è continua in un intorno del punto $(x_0, y_0)$.
    \item \textbf{Lipschitzianità:} $f$ è lipschitziana rispetto alla variabile $y$ (condizione garantita se $\frac{\partial f}{\partial y}$ esiste ed è continua nell'intorno).
\end{enumerate}

\subsection*{Applicazione al caso lineare del I ordine}

Per un'equazione lineare del tipo:
\[ y'(x) + a(x)y(x) = f(x) \]

Possiamo riscriverla in forma normale come:
\[ y'(x) = -a(x)y(x) + f(x) = f(x,y) \]
dove $f(x,y) = -a(x)y + f(x)$.

Affinché questo problema sia risolvibile, richiediamo che $a(x)$ e $f(x)$ siano continue per i seguenti motivi:
\begin{itemize}
    \item \textbf{Esistenza:} Se $a(x)$ e $f(x)$ sono continue, allora $f(x,y) = -a(x)y + f(x)$ è una funzione continua. Ciò garantisce l'esistenza della soluzione.
    \item \textbf{Unicità:} La derivata parziale $\frac{\partial f}{\partial y} = -a(x)$ è continua (poiché $a$ è continua per ipotesi). Questo implica che $f$ è localmente lipschitziana rispetto a $y$, garantendo l'unicità della soluzione.
    \item \textbf{Integrabilità:} La continuità di $a(x)$ e $f(x)$ è necessaria per l'applicazione delle formule risolutive, che richiedono il calcolo di integrali definiti delle funzioni stesse.
\end{itemize}

\textbf{7. Enunciare e dimostrare {\color{red}il teorema} per rappresentare {\color{red}l'integrale generale} di una EDO lineare del I ordine (su un intervallo).}
\begin{teorema}[Rappresentazione di un integrale generale di una EDO lineare completa]
L'integrale generale di una EDO lineare di ordine n definita su un intervallo $I = [a,b]$ del tipo  $y'(x) + a(x)y(x) = f(x)$ è dato dalla somma dell'integrale generale dell'omogenea associata ($y'(x) + a(x)y(x) = 0$) ed una curva integrale (una soluzione particolare) della EDO lineare non omogenea in forma normale ($y'(x) + a(x)y(x) = f(x)$):
\[
    y(x) = z (x) + \bar{y} (x)
\]
dove $x \in I$ e $y(x)$ è una soluzione qualsiasi della EDO lineare di ordine n, $z(x)$ è una soluzione qualsiasi della EDO lineare omogenea associata di ordine n e $\bar{y}(x)$ è una soluzione particolare  della EDO lineare di ordine n
\end{teorema}

\textbf{\color{thmcolor}DIMOSTRAZIONE}

La dimostrazione per $n=1$ è valida anche per $n$ di ordine superiore

\textbf{\color{thmcolor}Parte 1} Mostriamo che $z(x) = y(x) - \bar{y}(x)$ è soluzione dell'omogenea.
\begin{align*}
y'(x) + a(x)y(x) &= f(x) \quad \text{(soluzione qualsiasi della completa)} \\
\bar{y}'(x) + a(x)\bar{y}(x) &= f(x) \quad \text{(soluzione particolare della completa)}
\end{align*}

Sottraiamo la seconda equazione dalla prima, membro a membro:
\begin{align*}
[y'(x) + a(x)y(x)] - [\bar{y}'(x) + a(x)\bar{y}(x)] &= f(x) - f(x) \\
y'(x) + a(x)y(x) - \bar{y}'(x) - a(x)\bar{y}(x) &= 0 \\
y'(x) - \bar{y}'(x) + a(x)y(x) - a(x)\bar{y}(x) &= 0 \quad \text{(ri-ordino)} \\
[y'(x) - \bar{y}'(x)] + a(x)[y(x) - \bar{y}(x)] &= 0 \quad \text{(raccolgo $a(x)$)}
\end{align*}

Usando la linearità della derivata: $(y - \bar{y})' = y' - \bar{y}'$, otteniamo:
\begin{align*}
[y(x) - \bar{y}(x)]' + a(x)[y(x) - \bar{y}(x)] &= 0
\end{align*}

Ponendo $z(x) = y(x) - \bar{y}(x)$:
\begin{align*}
z'(x) + a(x)z(x) &= 0
\end{align*}

Quindi $z(x)$ è soluzione dell'omogenea perché abbiamo dimostrato che la differenza è soluzione dell'equazione omogenea associata.
\vskip 0.2cm
\textbf{\color{thmcolor}Parte 2} Mostriamo che $y(x) = z(x) + \bar{y}(x)$ è soluzione della completa.
\begin{align*}
z'(x) + a(x)z(x) &= 0 \quad \text{(soluzione dell'omogenea)} \\
\bar{y}'(x) + a(x)\bar{y}(x) &= f(x) \quad \text{(soluzione particolare della completa)}
\end{align*}

Sommiamo le due equazioni membro a membro:
\begin{align*}
[z'(x) + a(x)z(x)] + [\bar{y}'(x) + a(x)\bar{y}(x)] &= 0 + f(x) \\
z'(x) + a(x)z(x) + \bar{y}'(x) + a(x)\bar{y}(x) &= f(x) \\
z'(x) + \bar{y}'(x) + a(x)z(x) + a(x)\bar{y}(x) &= f(x) \quad \text{(ri-ordino)} \\
[z'(x) + \bar{y}'(x)] + a(x)[z(x) + \bar{y}(x)] &= f(x) \quad \text{(raccolgo $a(x)$)}
\end{align*}

Usando la linearità della derivata: $(z + \bar{y})' = z' + \bar{y}'$, otteniamo:
\begin{align*}
[z(x) + \bar{y}(x)]' + a(x)[z(x) + \bar{y}(x)] &= f(x)
\end{align*}

Ponendo $y(x) = z(x) + \bar{y}(x)$:
\begin{align*}
y'(x) + a(x)y(x) &= f(x)
\end{align*}

Quindi $y(x) = z(x) + \bar{y}(x)$ è soluzione della completa. 

\hfill{\color{thmcolor}$\square$}
\vskip 0.2cm

\textbf{8. Qual è la {\color{red}rappresentazione alternativa} dell'integrale generale e perché si usa?}\\
La rappresentazione alternativa dell'integrale generale $y'(x) + a(x)y(x) = f(x)$ è
\begin{center}
     $\int y(x) = \int z(x) + \int \bar{y}(x)$
\end{center}
Informalmente, per trovare tutte le soluzioni della EDO lineare è necessario sommare la soluzione generale dell'omogenea associata e la soluzione nota dell’equazione di partenza.
\subsubsection{Ricerca dell'integrale generale dell'omogena z(x)}
\textbf{9. Come si determina {\color{red}l'integrale generale dell'omogenea associata}?}\\
L'integrale della omogenea associata $y'(x) + a(x)y(x) =0$ si scrive nella forma 
\begin{center}
    $y(x) = y(x,c) = ce^{-A(x)} = ce^{-\int a(x)dx} $ con $c \in \mathbb{R}$
\end{center}
con $a(x)$ continua in $[a,b]$ e $A(x)$ derivabile sull'intervallo $[a,b]$ tale che $A'(x)=a(x)$ su $[a,b]$, allora $A(x)$ è \textbf{una} primitiva di $a(x)$.

\textbf{\color{thmcolor}DIMOSTRAZIONE}

Sia $A(x) = \int a(x)\,dx$, primitiva di $a(x)$ fissata una volta per tutte.
Si moltiplica ambo i membri di $y'(x) + a(x)y(x) =0$ per $e^{A(x)} = e^{\int a(x)\,dx}$ perché l'esponenziale ha la derivata proporzionale a se stesso e permette di trasformare $y'(x) + a(x)y(x) =0$ in una derivata del prodotto, e quindi si ottiene
\[
\underbrace{e^{A(x)}y'(x) + e^{A(x)}a(x)y(x)}_{[e^{A(x)}y(x)]'} = 0,
\]
essendo la derivata di una costante uguale 0 ci dice che 
\[
e^{A(x)}y(x) = c
\]
\[
\frac{\cancel{e^{A(x)}} y(x)}{\cancel{e^{A(x)}}} = \frac{c}{e^{A(x)}}
\]
\[
y(x) = \frac{c}{e^{A(x)}}
\]
\[
y(x) = ce^{-A(x)}
\]

allora (è ottenuta l'integrale generale dell'omogenea)
\[
y(x) = ce^{-A(x)} = ce^{-\int a(x)\,dx}, \quad c \in \mathbb{R}. 
\]
Infatti
\[
\left(e^{-A(x)}\right)' = e^{-A(x)}[-a(x)],
\]
dunque
\[
\left(e^{-A(x)}\right)' + e^{-A(x)}a(x) = 0.
\] 
\hfill{\color{thmcolor}$\square$}

L'insieme delle soluzioni dell'equazione lineare di ordine 1 dell'omogenea associata costituisce uno spazio vettoriale\footnote{Questo perché soddisfa due proprietà di linearità, ossia la somma di due soluzioni è ancora una soluzione e il prodotto di una soluzione per una costante è una soluzione} di dimensione 1 e per trovare gli elementi di tale spazio:
\begin{itemize}
    \item Basta trovare una soluzione particolare non nulla $z_0(x) = e^{-A(x)}$;
    \item Questa $z_0(x)$ funge da base dello spazio;
    \item Ogni altra soluzione è uno suo multiplo e si può scrivere come $y(x)=c e^{-A(x)}$
\end{itemize}

Invece, la condizione di indipendenza lineare per il secondo ordine viene solitamente verificata attraverso il determinante della matrice Wronskiana.

\subsubsection{Ricerca di un soluzione nota della EDO non omogenea del primo ordine}
\textbf{10. In cosa consiste {\color{red}il metodo di variazione della costante}?}\\
Dopo aver calcolato l'integrale dell'omogenea il passo successivo è quello di ricercare l'integrale noto $\bar{y}(x)$ della stessa EDO non omogenea completa. Essa può essere trovata o "ad occhio" analizzando il termine noto o con il metodo di variazione di una costante.

\begin{teorema}[Metodo di variazione di una costante]
Partendo dall'equazione $\bar{y}'(x) + a(x)\bar{y}(x) = f(x)$ ottengo $\bar{y}(x) = e^{-A(x)} \int f(x) e^{A(x)} dx$.
\end{teorema}
\textbf{\color{thmcolor}DIMOSTRAZIONE}

Consideriamo la soluzione nella forma:
\[
\bar{y}(x) = c(x)e^{-A(x)}
\]
dove $c(x) \in C^1(I)$ ed è una funzione perché non mi basta più una costante $c$ fissa per strutturare la soluzione.
Essendo $\bar{y}(x)$ una soluzione particolare della EDO completa del primo ordine, è possibile trasformare la 
\[
\bar{y}'(x) + a(x)\bar{y}(x) = f(x), \quad x \in [a, b].
\]
Sostituendo al suo interno $\bar{y}(x) = c(x)e^{-A(x)}$, ottengo la EDO nella forma
\[
(c(x)e^{-A(x)})'- a(x)c(x)e^{-A(x)}
\]
Quindi, si deriva $(c(x)e^{-A(x)})'$ e la forma completa diventa
\[
c'(x)e^{-A(x)} - c(x)a(x)e^{-A(x)} + a(x)c(x)e^{-A(x)} = f(x),
\]
Con un passaggio algebrico si trasforma
\[
c'(x)e^{-A(x)} - \cancel{c(x)a(x)e^{-A(x)}} + \cancel{a(x)c(x)e^{-A(x)}} = f(x),
\]
ovvero
\[
c'(x)e^{-A(x)} = f(x),
\]
Dividendo tutto per $e^{-A(x)}$ e poi spostando $e^{-A(x)}$ al numeratore, ottengo la forma definitiva
\[
c'(x) = e^{A(x)}f(x).
\]

Integrando $c'(x)$, infine, si ottiene:
\[
c(x) = \int e^{A(x)}f(x) \, dx.
\]

Pertanto, sostituendo in $\bar{y}(x) = c(x)e^{-A(x)}$, si ottiene la definizione dell'integrale generale particolare $\bar{y}(x)$ della EDO completa non omogenea nella forma
\[
\bar{y}(x) = e^{-A(x)} \int e^{A(x)}f(x) \, dx.
\]
\hfill{\color{thmcolor}$\square$}

\textbf{11. Qual è {\color{red}la formula finale dell'integrale generale} della EDO lineare di primo ordine?}\\
Per concludere, per calcolare l'integrale generale della EDO non omogenea lineare si usa
\begin{center}
    $y(x) = ce^{-A(x)} + e^{-A(x)} \int f(x) e^{A(x)} dx$
\end{center}

\begin{osservazione}
$A(x)$ è una primitiva di $a(x)$ che viene scelta \underline{una e una sola volta} e non occorre aggiungere una costante arbitraria in quanto, nella formula finale, è già inclusa la costante $c$; non occorre aggiugere nemmeno una costante additiva nel calcolo dell'integrale particolare. Tutto ciò è dimostrabile ripetendo le dimostrazione con l'aggiunta di un $k$.
\end{osservazione}

\subsection{Il Problema di Cauchy per EDO lineari di I Ordine}

\textbf{12. Cos'è e come si rappresenta {\color{red}un problema di Cauchy}   per EDO lineari?}
\[
\begin{cases}
      y'(x) + a(x)y(x) =& f(x)  \\
      y(x_{0})         =& y_{0}                
\end{cases}
\]

Il problema di Cauchy per EDO lineari a coefficenti costanti ci permette di determinare la costante c che compare nell'integrale generale dell'omogenea associata, imponendo una condizione iniziale $y(x_0)=y_0$ con $x_0 \in [a,b]$.\\
Definiamo la primitiva $A(x)$ attraverso l'integrale definito con estremo inferiore $x_0$:
\[
A(x) = \int_{x_0}^x a(t) \, dt
\]
Per il teorema fondamentale del calcolo integrale, questa scelta implica che:
\[
A(x_0) = \int_{x_0}^{x_0} a(t) \, dt = 0
\]
Sostituendo tale primitiva nella soluzione generale $y(x) = c e^{-A(x)}$, otteniamo per $x = x_0$:
\[
y(x_0) = c e^{-A(x_0)} = c e^0 = c
\]
Imponendo la condizione iniziale $y(x_0) = y_0$, risulta $c = y_0$. La soluzione unica del problema di Cauchy è dunque:
\[
y(x) = y_0 e^{-\int_{x_0}^x a(t) \, dt}+e^{-\int_{x_0}^x a(t) \, dt}\int_{x_0}^x e^{\int_{x_0}^x a(t) \, ds}f(s)ds\
\]

\textbf{\color{thmcolor}DIMOSTRAZIONE}\\
Moltiplichiamo ambedue i membri dell'equazione differenziale per il fattore integrante $e^{A(x)}$:
\[
e^{A(x)} y'(x) + a(x) e^{A(x)} y(x) = e^{A(x)} f(x)
\]

Osserviamo che il membro di sinistra è lo sviluppo della derivata del prodotto tra la funzione incognita e il fattore integrante:
\[
\frac{d}{dx} \left[ e^{A(x)} y(x) \right] = e^{A(x)} f(x)
\]

Integrando entrambi i membri rispetto alla variabile di integrazione $s$ nell'intervallo $[x_0, x]$ otteniamo:
\[
\int_{x_0}^x \frac{d}{ds} \left[ e^{A(s)} y(s) \right] ds = \int_{x_0}^x e^{A(s)} f(s) \, ds
\]

Applicando il Teorema Fondamentale del Calcolo Integrale al membro di sinistra:
\[
\left[ e^{A(s)} y(s) \right]_{x_0}^x = \int_{x_0}^x e^{A(s)} f(s) \, ds
\]
\[
e^{A(x)} y(x) - e^{A(x_0)} y(x_0) = \int_{x_0}^x e^{A(s)} f(s) \, ds
\]

Poiché abbiamo definito $A(x_0) = 0$, ne consegue che $e^{A(x_0)} = e^0 = 1$. Sostituendo la condizione iniziale $y(x_0) = y_0$:
\[
e^{A(x)} y(x) - y_0 = \int_{x_0}^x f(s) e^{A(s)} \, ds
\]

Isolando $y(x)$ e moltiplicando tutto per $e^{-A(x)}$, si ottiene la formula risolutiva esplicita:
\[
y(x) = y_0 e^{-\int_{x_0}^x a(t) dt} + e^{\int_{x_0}^x a(t) dt} \int_{x_0}^x e^{-\int_{x_0}^x a(t) ds} f(s) ds =e^{-A(x)} \left[ y_0 + \int_{x_0}^x f(s) e^{A(s)} \, ds \right]  
\]
\hfill{\color{thmcolor}$\square$}

\textbf{13. Quali osservazioni posso fare {\color{red}sull'esistenza e sull'unicità della soluzione} di un problema di {\color{red}Cauchy} di primo ordine? }

Le condizioni sufficienti per cui un problema di Cauchy abbia una soluzione e che essa sia unica sono
    \begin{itemize}
    \item \textbf{Per l'esistenza:} È sufficiente che $f$ sia \textbf{continua} rispetto a $x$ e $y$ in un intervallo contenente il punto $x_0$ dove sono assegnate le condizioni iniziali;

    \item \textbf{Per l'unicità:} Oltre alla continuità, è necessario che $f$ sia \textbf{derivabile rispetto alla seconda componente} (la variabile $y$) e che tale \textbf{derivata sia continua}.
    \end{itemize}
Quindi, se $f$ è continua e derivabile rispetto a $y$ con derivata continua in un intorno di $(x_0, y_0)$, allora esiste un'unica soluzione $y(x)$ del problema di Cauchy, definita su un opportuno intervallo contenente $x_0$.

\textbf{14. Cosa si intende per {\color{red} soluzioni in piccolo o in grande}?}
\begin{itemize}
\item \textbf{Soluzione in piccolo (locale):} La soluzione esiste ed è definita solo in un \textbf{intorno del punto iniziale} $x_0 \in I$, ovvero l'intervallo in cui è definita l'EDO;

\item \textbf{Soluzione in grande (globale):} La soluzione esiste ed è definita su \textbf{tutto l'intervallo di definizione} delle funzioni coefficienti, che può essere tutto $\mathbb{R}$ o un intervallo più ampio.
\end{itemize}

La differenza fondamentale è che una soluzione in piccolo esiste solo localmente vicino al punto iniziale, mentre una soluzione in grande può essere prolungata su un intervallo molto più ampio o addirittura su tutto $\mathbb{R}$.

\textbf{15. Cosa si intende per {\color{red} intervallo massimale}?}\\
L'\textbf{intervallo massimale di esistenza} di una soluzione è il più grande intervallo contenente il punto iniziale $x_0$ nel quale la soluzione è definita e soddisfa l'equazione differenziale.

Può essere limitato o illimitato:
\begin{itemize}
\item \textbf{Può essere tutto} $\mathbb{R}$ se le funzioni coefficienti $a(x)$ e $f(x)$ sono definite e continue su tutto $\mathbb{R}$ e la soluzione non presenta singolarità.

\item \textbf{Può essere limitato} se:
\begin{itemize}
\item Le funzioni coefficienti non sono definite su tutto $\mathbb{R}$ (ad esempio: se $a(x) = \frac{1}{\sqrt{x}}$, allora $I = (0, +\infty)$)
\item La soluzione presenta singolarità o comportamenti asintotici che impediscono il prolungamento
\end{itemize}
\end{itemize}

Da cosa dipende:

\begin{enumerate}
\item Dall'\textbf{intervallo di definizione} delle funzioni $a(x)$ e $f(x)$
\item Dal \textbf{comportamento della soluzione} stessa (presenza di singolarità, esplosioni in tempo finito)
\item Dalle \textbf{condizioni iniziali} $(x_0, y_0)$ che possono influenzare quando e dove la soluzione cessa di esistere
\end{enumerate}

L'intervallo massimale è quindi determinato dalla forma delle funzioni coinvolte nell'EDO e dal punto iniziale scelto. Non è detto che le soluzioni espresse dall'integrale generale dell'equazione siano tutte definite sullo stesso insieme al variare dei parametri o delle condizioni iniziali.

\section{EDO a Variabili Separabili}
\textbf{16. Cosa si intende per {\color{red}un'equazione a variabili separabili}?}
\begin{definizione}[Equazioni differenziali a variabili separabili di primo ordine] Una EDO a variabili separabili in forma normale
\begin{center}
    $y'(x) = f(x) g(y(x))$
\end{center}
dove $f: I \in \mathbb{R} \to \mathbb{R}$ e $g: J \in \mathbb{R} \to \mathbb{R}$ sono continue nei loro domini.
\end{definizione}

\textbf{17. Perché una EDO lineare del primo ordine {\color{red}omogenea è un'equazione a variabili separabili}?}\\
Un'EDO lineare omogenea del primo ordine ha la forma:
\[
y'(x) + a(x)y(x) = 0
\]

Riscriviamola esplicitamente come:
\[
\frac{dy}{dx} = -a(x)y(x)
\]

Questa può essere separata dividendo per $y$ (assumendo $y \neq 0$) e moltiplicando per $dx$:
\[
\frac{dy}{y} = -a(x) \, dx
\]

Ora le variabili sono \textbf{separate}: a sinistra compare solo $y$, a destra solo $x$. Integrando entrambi i membri:
\[
\int \frac{dy}{y} = \int -a(x) \, dx
\]
\[
\ln|y| = -A(x) + c
\]

dove $A(x) = \int a(x) \, dx$. Esponenziando:
\[
y(x) = ce^{-A(x)}
\]

Quindi un'EDO lineare omogenea del primo ordine è sempre riconducibile alla forma separabile $\frac{dy}{y} = g(x) \, dx$ con $g(x) = -a(x)$.

\textbf{17. Cosa si intende per {\color{red}soluzioni singolari}?}\\
Sono soluzioni dell'equazione differenziale che non sono ottenibili dall'integrale generale per nessun valore della costante arbitraria $c$.

Si individuano attraverso le equazioni a variabili separabili della forma:
\[
\frac{dy}{dx} = f(x)g(y(x))
\]

Le soluzioni singolari si ottengono dagli zeri della funzione $g(y(x))$. Se $g(y_0) = 0$, allora $y(x) = y_0$ (funzione costante) è una soluzione dell'equazione.

Durante la separazione delle variabili, quando scriviamo:
\[
\frac{dy}{g(y)} = f(x) \, dx
\]

dividiamo per $g(y)$, e questa operazione è valida solo se $g(y) \neq 0$. Pertanto, le soluzioni corrispondenti a $g(y) = 0$ vengono \textbf{perse} nel processo di separazione e devono essere verificate separatamente.
Le soluzioni singolari sono importanti perché la loro presenza può influenzare l'unicità delle soluzioni di problemi di Cauchy, infatti rappresentano soluzioni effettive dell'equazione differenziale, che non compaiono\footnote{Non si possono ottenere dall'integrale generale per alcun valore finito di $c$, ma devono essere considerate separatamente per avere la famiglia completa di tutte le soluzioni dell'EDO.} nell'integrale generale.

\textbf{18. Come si risolve {\color{red}un PdC a variabili separabili}?}
\begin{teorema}[Algoritmo per la separazione delle variabili] Partendo da  $y'(x) = f(x) g(y(x))$
\end{teorema}
\begin{enumerate}
    \item Determina eventuali $\bar{y} \in \mathbb{R}$ per cui $g(\bar{y}) = 0$ dove $y(x) = \bar{y}$
    è la soluzione del PdC. Queste sono le soluzioni singolari della EDO;
    \item Si considera $y \neq \bar{y}$ si divide tutto per $g(y(x))$ seperando, quindi, la EDO (dove $g(y(x)) \neq 0$ dato che $y \neq \bar{y}$)
    \begin{center}
    \vspace{-0.7cm}
        \[\frac{y'(x)}{g(y(x)} = \frac{f(x) \bcancel{g(y(x)}}{\bcancel{g(y(x)}}  \]
    \end{center}
    \item Si integra ambo ai lati per x per ottenere le soluzioni
    \begin{center} 
    \vspace{-0.7cm}
            \[\int \frac{y'(x)}{g(y(x))}\,\mathrm{d}x \;=\; \int f(x)\,\mathrm{d}x\]
     \end{center}
     \item Si usa la regola della sostituzione ponendo $y = y(x)$ e $\mathrm{d}y = y'(x) \mathrm{d}$
     \begin{center} 
     \vspace{-0.7cm}
            \[\int \frac{1}{g(y)}\,\mathrm{d}y \;=\; \int f(x)\,\mathrm{d}x\]
     \end{center}
     \item Sia $G(x)$ la primitiva di $\frac{1}{g(y)}$ e sia $F(x)$ di $f(x)$
     \begin{center}
        $ G(x) = F(x) + c $
     \end{center}
     \item Per concludere, si esplicita $y(x)$ è la soluzione del PdC, con $G$ invertibile si ha
     \begin{center}
         $y(x) = G^{-1}(x)[F(x)+c ]$
     \end{center}
\end{enumerate}
\hfill{\color{thmcolor}$\square$}

\textbf{19. Perché la soluzione è di classe {\color{red}$C^1$}?}

La soluzione $y(x)$ deve essere di classe $C^1(I)$, ovvero \textbf{continuamente derivabile} sull'intervallo $I$. Per definizione, una funzione derivabile è continua.
La \textbf{continuità della soluzione} è garantita dal fatto che  $y(x)$ deve essere derivabile nell'intervallo di definizione; la derivabilità implica la continuità
e infine l'equazione differenziale stessa richiede che $y'(x)$ esista, il che implica la continuità di $y(x)$.

Se la soluzione è definita \textbf{localmente in} $x_0$, ovvero deve passare per il punto iniziale $x_0$ e deve essere definita in un intorno di $x_0$, che è necessariamente un intervallo.

Quindi le ipotesi di continuità su $f$ garantiscono che la soluzione non possa "saltare" dei punti: se $f$ è continua, allora la derivata $y'(x) = f(x, y(x))$ è continua, e una funzione con derivata continua non può presentare discontinuità o salti.

\textbf{20. Qual è {\color{red}il significato fisico e matematico} del PdC?}
\begin{itemize}
    \item \textbf{Fisico:} Il problema di Cauchy rappresenta un'evoluzione rispetto al tempo (o rispetto alla variabile indipendente $x$), che è una variabile continua. Quindi se è trovato un tempo in cui il sistema perde significato non ha senso considerare il prima o il dopo. Allora viene considerato l'intervallo massimale contenente l'istante iniziale in cui il sistema ha significato.

    \item \textbf{Matematico:} Non è possibile considerare una soluzione $y(x)$ al PdC su intervalli disgiunti. Per questo, la condizione iniziale determina l'esistenza della soluzione e l'unicità di essa nell'insieme che la contiene.
\end{itemize}

\section{EDO di II Ordine}
\textbf{21. Che cosa si intende per {\color{red}EDO lineare di secondo ordine} e in che forma si scrive?}
\begin{definizione}[EDO lineare completa di II ordine]Una EDO lineare di II ordine si dice lineare se viene rappresentata nella forma
\begin{center}
    $a_2(x)y''(x) + a_1(x)y'(x) + a_0(x)y(x)= f(x)$
\end{center}
dove $a_i$ (con $i=0,1,2$)e $f(x)$ sono costanti (ovvero appartengono a $C^0(I)$)
\end{definizione}
\begin{definizione} Basandoci sulla forma della EDO lineare di II ordine, ponenedo $a_2(x) = 1$ possiamo scrivere l'EDO in forma nomale e la sua omogenea associata
\begin{enumerate}
    \item 
    \begin{center}
     $y''(x) + a_1(x)y'(x) + a_0(x)y(x)= f(x)$
    \end{center}
    \item 
    \begin{center}
     $y''(x) + a_1(x)y'(x) + a_0(x)y(x)= 0$
    \end{center}
\end{enumerate}
\end{definizione} 
Per calcolare una EDO lineare del II ordine, come per una EDO di I ordine, bisogna trovare l'integrale dell'omogena associata e sommarlo all'integrale particolare della non omogenea, ottenendo l'integrale della completa. Tutto ciò si può riscrivere nella forma: \[\int generale \;=\; \int omogenea + \int particolare\]

Come già detto, lo spazio delle soluzioni di una EDO di ordine n = 2 è uno spazio vettoriale di dimensione n = 2, quindi per trovare una soluzione qualsiasi dell’omogenea servono n = 2 soluzioni linearmente
indipendenti.

\subsubsection{Soluzioni della omogenea associata z(x)}
\textbf{22. Come è fatto {\color{red}l'integrale generale di un'EDO lineare omogenea} del secondo ordine?}\\
Se otteniamo come soluzioni su $I = [a,b]$ della omogenea associata $y''(x) + a_1(x)y'(x) + a_0(x)y(x)= 0$ le funzioni $y_1(x)$ e $y_2(x)$ possiamo dire che entrambe sono linearmente indipendenti e che ogni altra soluzione è una combinazione lineare delle due "funzioni-soluzioni".\\
Il motivo è la proprietà della linearità della EDO: dato un operatore $L: C^n (I) \to C^0(I)$ che associa ad ogni funzione $\phi \in C^n(I)$ una funzione continua $L(\phi(x)):= a_n\phi^n(x)+a_{n-1}\phi^{n-1}(x)+...+a_1\phi'(x)+a_0\phi(x)$, quindi segue che se $\phi_1$ e $\phi_2$ sono soluzioni, anche la loro combinazione lineare è soluzione.
Allora l'integrale della omogenea associata è rappresantabile come \begin{center}
    $z(x, c_1, c_2) = c_1y_1(x) + c_2y_2(x)$ 
\end{center}Al variare di $c \in \mathbb{R}$.\\

La EDO lineare omogenea di II grado può essere scritta in forma compatta tramite l'operatore $L(\phi(x)):= a\phi''(x)+b\phi'(x)+c\phi(x)$ con $\phi \in C^2(I)$ come $L(y(x)) = 0$.\\ Tutto ciò significa che risolvere $ay''(x) + by'(x) + cy(x)= 0$ significa trova la $y$ tale $ay''(x) + by'(x) + cy(x)= L(y(x)) = 0$.

\subsubsection{Indipedenza Lineare}
\textbf{22. Quando due soluzioni si dicono {\color{red}linearmente indipendenti} su un intervallo? Cos'è il Wronskiano e come si usa?}\\
Per comprendere meglio il concetto di base costituito dalle due "funzioni-soluzioni" $y_1(x)$ e $y_2(x)$, bisogna provare che esse siano linearmente indipendenti.

\begin{definizione}[Matrice Wroskiana] Date due funzioni differnziabili $y_1(x)$ e $y_2(x)$, la matrice Wroskiana è 
\[
\begin{vmatrix}
        y_1(x) & y_2(x)\\ 
        y_1'(x) & y_2'(x)
    \end{vmatrix}
\]
\end{definizione}

\begin{definizione}[Wroskiano]
Il determinante Wroskiano o Wronskiano è il determinante di una matrice formata da due funzioni e dalle loro derivate prime:
    $W[\ y_1,y_2 ]\ = det (W(x)) =$ 
    \[
    \begin{vmatrix}
        y_1(x) & y_2(x)\\ 
        y_1'(x) & y_2'(x)
    \end{vmatrix}
    \]
     $= y_1(x) y_2'(x) - y_1'(x) y_2(x)$
\end{definizione}
Considerate le soluzioni di una equazione omogenea, il Wronskiano è una funzione che dipende da x. Se le funzioni considerate nel Wronskiano sono soluzioni del problema, il determinante è diverso da 0 e l’essere diverso da 0 indica che le funzioni sono linearmente indipendenti.

\textbf{23. Perché è importante definire {\color{red} sistema fondamentale di soluzioni}?}\\
Quindi, se $y_1(x)$ e $y_2(x)$ sono soluzioni su $I = [a,b]$ della EDO omogenea associata allora ogni soluzione della omogenea associata è una loro combinazione lineare: $y_1(x)$ e $y_2(x)$ formano un sistema fondamentale di soluzioni. Ciò significa che 
\begin{center}
    $c_1y_1(x) + c_2y_2(x) \Leftrightarrow c_1 = c_2 = 0$  
\end{center}
con \{$y_1(x),y_2(x)$\} come sistema fondamentale di soluzioni.\\
\vspace{-1em}
\begin{itemize}
\item 
Gli elementi di $\mathbb{R}^n$ sono rappresantabili tramite la base canonica (ovvero una base ortonormale). Un vettore può essere rappresentato come combinazione lineare con la base canonica, ad esempio $(1,2) \in \mathbb{R}^2$ può essere espresso come $1e_1 + 2e_2 = u =(1,2)$. Lo stesso vale con \{$y_1(x),y_2(x)$\}: le due funzioni sono due soluzioni del problema omogeneo ed è possibile dimostrare con la proprietà della linearità che la loro combinazione lineare è anche la soluzione. Dato che l'obiettivo è trovare tutte le soluzioni (spazio di soluzioni), è sufficiente avere due soluzioni indipendenti (la EDO è ordine II e lo spazio delle soluzioni è di dimenzione 2). 
\item 
Dall'Algebra Lineare: per trovare una soluzione qualsiasi del problema omogeneo è sufficiente trovare due soluzioni linearmente indipendenti del problema, che formeranno un sistema fondamentale di soluzioni.
\end{itemize}

\textbf{24. Cos'è {\color{red} EDO lineare completa di II ordine a coefficenti costanti}?}
\begin{definizione}[EDO lineare completa di II ordine a coefficenti costanti] Una EDO lineare completa di II ordine a coefficenti costanti si scrive  
\begin{center}
    $ay''(x) + by'(x) + cy(x)= f(x)$
\end{center}
\begin{itemize}
    \item $a, b, c \in \mathbb{R}$ con $a\neq0$
    \item $a_2(x) = a, a_1(x) = b, a_0(x) = c $ e $f(x)$ sono costanti (ovvero appartengono a $C^0(I)$), con $I \subseteq \mathbb{R}$)
\end{itemize} 
\end{definizione}

\subsection{Ricerca dell'integrale qualsiasi z(x) della EDO omogenea associata}
\textbf{25. Cosa si intende per {\color{red}equazione caratteristica}?}

La forma della sua omogenea associata è $ay''(x) + by'(x) + cy(x)= 0$
\begin{enumerate}
    \item Se $b = c = 0$ (identicamente nulle) l'equazione diventa $ay'' = 0$, quindi $y'(x) = c_1$ integrando si ottiene $z(x) = z(x, c_1, c_2) = c_1+c_2$ con $c_1,c_2 \in \mathbb{R}$
    \item Se $b$ e $c$ non sono contemporaneamente nulle, per trovare l'integrale generale della omogenea viene associata alla EDO un'equazione algebrica $p(\lambda)$ di II grado in $\mathbb{C}$ della forma
    \begin{center}
        $a\lambda^2+b\lambda +c= 0$
    \end{center}
    Con $\lambda \in \mathbb{R}$\\
    Formalmente le soluzioni di $p(\lambda)$ sono date dalla formula risolutiva $\lambda_1,_2 = \frac{-b \pm \sqrt{b^2-4ac}}{2a}$
\end{enumerate}

\textbf{26. Quali sono i tre casi che definiscono {\color{red}le soluzioni della EDO di secondo grado omogenea} lineare a coefficenti costanti?}

\vspace{0.3em}
Date le due radici $\lambda_1,_2 = \frac{-b \pm \sqrt{b^2-4ac}}{2a}$ ci sono tre disinti casi dove le soluzioni della EDO lineare omogenea di II ordine a coefficenti costanti:
\begin{enumerate}
    \item \textbf{Caso $\Delta > 0$} \\\textbf{Soluzioni reali distinte:} $\lambda_1,_2 \in \mathbb{R}$ e $\lambda_1 \neq \lambda_2$\\
     $y_1(x) = e^{\lambda_1 x}$ e $y_2(x) = e^{\lambda_2 x}$\\
     \textbf{L'integrale generale dell'omogenea:}\begin{center}
         $z(x) = c_1(x)y_1(x)+c_2(x)y_2(x) = c_1e^{\lambda_1 x}+c_2e^{\lambda_2 x} $
     \end{center}
     \item \textbf{Caso $\Delta = 0$} \\\textbf{Soluzioni reali coincidenti:} $\lambda_1 = \lambda_2 = \lambda = \frac{-b}{2a} \in \mathbb{R}$\\
     \textbf{L'integrale generale dell'omogenea:}\begin{center}
         $z(x) = e^{\lambda_x}(c_1+c_2x) $
         \end{center}
    \item \textbf{Caso $\Delta < 0$} \\\textbf{Soluzioni complesse coniugate:} $\lambda_1,_2 = \alpha \pm i \beta $ con $i = \sqrt{-1}$, $\alpha = -\frac{b}{2a}$ e $\beta = \frac{\sqrt{-\Delta}}{2a}$\\
     \textbf{L'integrale generale dell'omogenea:}\begin{center}
         $z(x) = e^{\alpha x}(c_1\cos \beta x+c_2 \sin \beta x) $
         \end{center}
\end{enumerate}

\textbf{27. Enunciare il motivo e {\color{red} dimostrare} perché $y(x) = e^{\lambda x}$ è soluzione dell'omogenea $ay'' + by' + cy = 0$ se e solo se $\lambda$ soddisfa l'equazione caratteristica $a\lambda^2+b\lambda +c= 0$.}\\
Dire $\lambda$ è radice (zero) di $p(\lambda)$ è come dire che $y(x) = e^{\lambda x}$ è soluzione reale o complessa dell'equazione caratteristica.
\\
\textbf{\color{thmcolor}DIMOSTRAZIONE}

Si consideri l'operatore differenziale lineare del secondo ordine a coefficienti costanti:
\[
L(y) = ay'' + by' + cy
\]
Vogliamo dimostrare che una funzione esponenziale del tipo $y(x) = e^{\lambda x}$ è soluzione dell'equazione omogenea $L(y) = 0$ se e solo se $\lambda$ è radice del polinomio caratteristico $p(\lambda)$.

Sostituiamo la funzione $y(x) = e^{\lambda x}$ nell'operatore $L$. Calcoliamo innanzitutto le derivate della funzione:
\[
y(x) = e^{\lambda x}, \quad y'(x) = \lambda e^{\lambda x}, \quad y''(x) = \lambda^2 e^{\lambda x}
\]

Sostituendo nell'espressione dell'operatore $L(e^{\lambda x})$ otteniamo:
\[
L(e^{\lambda x}) = a(\lambda^2 e^{\lambda x}) + b(\lambda e^{\lambda x}) + c(e^{\lambda x})
\]

Possiamo ora raccogliere il termine comune $e^{\lambda x}$:
\[
L(e^{\lambda x}) = e^{\lambda x} (a\lambda^2 + b\lambda + c)
\]

Definiamo il polinomio caratteristico come $p(\lambda) = a\lambda^2 + b\lambda + c$. L'espressione diventa:
\[
L(e^{\lambda x}) = e^{\lambda x} \cdot p(\lambda)
\]

Poiché la funzione esponenziale $e^{\lambda x}$ non è mai nulla per alcun valore reale di $x$, l'uguaglianza $L(e^{\lambda x}) = 0$ è soddisfatta se e solo se il polinomio è nullo:
\[
L(e^{\lambda x}) = 0 \iff p(\lambda) = 0
\]
\hfill{\color{thmcolor}$\square$}

\textbf{28. Perché è necessario studiare l'equazione caratteristica in {\color{red}campo complesso} anche se l'EDO ha coefficienti reali?}

Anche quando l'EDO ha coefficienti reali, è necessario studiare l'equazione caratteristica in campo complesso per i seguenti motivi:

\begin{enumerate}
    \item \textbf{Esistenza delle soluzioni}: Il teorema fondamentale dell'algebra garantisce che ogni equazione polinomiale ha sempre soluzioni nel campo complesso $\mathbb{C}$, mentre nel campo reale $\mathbb{R}$ alcune equazioni potrebbero non avere soluzioni.
    \item \textbf{Completezza della soluzione}: Per costruire la soluzione generale completa dell'EDO, abbiamo bisogno di tutte le radici dell'equazione caratteristica, incluse quelle complesse.
\end{enumerate}

\textbf{29. Cosa garantisce {\color{red}il teorema fondamentale dell'algebra}?}\\
Il teorema fondamentale dell'algebra enuncia che sia
\[
p(z) = a_n z^n + a_{n-1} z^{n-1} + \dots + a_1 z + a_0,
\]
un polinomio di grado $n \geq 1$ con coefficienti complessi,
cioè $a_0, a_1, \dots, a_n \in \mathbb{C}$ e $a_n \neq 0$.
Allora esiste almeno un numero complesso $z_0 \in \mathbb{C}$
tale che
\[
p(z_0) = 0.
\]

Inoltre, il polinomio $p$ può essere fattorizzato come
\[
p(z) = a_n (z - z_1)(z - z_2)\cdots(z - z_n),
\]
dove $z_1, \dots, z_n \in \mathbb{C}$ sono le radici del polinomio,
contate con la loro molteplicità.\\
Il teorema fondamentale dell'algebra afferma che ogni polinomio non costante a coefficienti complessi
ha almeno una radice complessa. Equivalentemente, un polinomio di grado $n$ ha esattamente $n$ radici complesse, contando le molteplicità.
Considerando l'equazione caratteristica quadratica, sono:
\[
\lambda^2 + b\lambda + c = 0
\]
Possiamo dire che per il teorema fondamentale dell'algebra, ci viene garantito che esistono sempre esattamente 2 radici in $\mathbb{C}$ (contate con molteplicità).
Quindi concludendo il teorema garantisce che \textbf{non possiamo mai avere assenza di soluzioni}: l'equazione caratteristica ha sempre radici, anche se potrebbero essere complesse. 

\textbf{30. Dimostrare {\color{red}il teorema che riassume tutti e tre i casi}.}
\begin{teorema}[Integrale generale della EDO lineare omogenea di II grado a coefficenti costanti] L'integrale generale della EDO lineare omogenea di II grado a coefficenti costanti  $ay''(x) + by'(x) + cy(x)= f(x)$ è data da \begin{center}
    $z(x, c_1, c_2) = c_1y_1(x) + c_2y_2(x)$
\end{center} 
Al variare di $c \in \mathbb{R}$ e dove $y_1,_2(x)$ sono determinate dai tre casi distinti.
\end{teorema}

\textbf{\color{thmcolor}DIMOSTRAZIONE}\\
\textbf{Caso 1 \(\Delta > 0\) (Due radici reali distinte)} 

In questo caso il discriminante è positivo:
\[
\Delta = b^2 - 4ac > 0,
\]
quindi le radici dell'equazione caratteristica \(a\lambda^2 + b\lambda + c = 0\) sono due valori reali distinti: \(\lambda_1 \neq \lambda_2\), dove \(\lambda_1, \lambda_2 \in \mathbb{R}\).

Le soluzioni della EDO lineare omogenea di secondo grado a coefficienti costanti
\[
ay''(x) + by'(x) + cy(x) = 0
\]
sono
\[
y_1(x) = e^{\lambda_1 x} \quad \text{e} \quad y_2(x) = e^{\lambda_2 x}.
\]

\textbf{{\color{thmcolor}Passo 1:} verifica dell'indipendenza lineare tramite Wronskiana}

Per dimostrare che \(y_1(x)\) e \(y_2(x)\) formano un sistema fondamentale di soluzioni, dobbiamo verificare che siano linearmente indipendenti. Questo si fa calcolando il determinante della matrice Wronskiana:
\[
W(y_1(x), y_2(x)) = \begin{vmatrix} y_1(x) & y_2(x) \\ y'_1(x) & y'_2(x) \end{vmatrix}.
\]

Calcoliamo le derivate:
\[
y'_1(x) = \lambda_1 e^{\lambda_1 x}, \quad y'_2(x) = \lambda_2 e^{\lambda_2 x}.
\]

Sostituiamo nella Wronskiana:
\[
W(y_1(x), y_2(x)) = \begin{vmatrix} e^{\lambda_1 x} & e^{\lambda_2 x} \\ \lambda_1 e^{\lambda_1 x} & \lambda_2 e^{\lambda_2 x} \end{vmatrix}.
\]

Calcoliamo il determinante usando la regola \(\det = ad - bc\):
\[
W(y_1(x), y_2(x)) = e^{\lambda_1 x} \cdot \lambda_2 e^{\lambda_2 x} - e^{\lambda_2 x} \cdot \lambda_1 e^{\lambda_1 x}
\]
\[
= \lambda_2 e^{\lambda_1 x + \lambda_2 x} - \lambda_1 e^{\lambda_1 x + \lambda_2 x}
\]
\[
= \lambda_2 e^{(\lambda_1+\lambda_2)x} - \lambda_1 e^{(\lambda_1+\lambda_2)x}
\]
\[
= (\lambda_2 - \lambda_1) e^{(\lambda_1+\lambda_2)x}.
\]

Poiché \(\lambda_1 \neq \lambda_2\) (per \(\Delta > 0\)), abbiamo \(\lambda_2 - \lambda_1 \neq 0\), e poiché \(e^{(\lambda_1+\lambda_2)x} > 0\) per ogni \(x\), concludiamo che
\[
W(y_1(x), y_2(x)) \neq 0.
\]

Quindi \(y_1(x)\) e \(y_2(x)\) sono linearmente indipendenti.

\textbf{{\color{thmcolor}Passo 2:} dimostrazione che ogni soluzione è combinazione lineare di \(y_1\) e \(y_2\)}

Sia \(z(x)\) una soluzione qualsiasi dell'equazione omogenea. Scriviamo \(z(x)\) nella forma
\[
z(x) = e^{\lambda_1 x} u(x),
\]
dove \(u(x)\) è una funzione da determinare.

Poiché \(z(x)\) è soluzione dell'equazione differenziale, deve soddisfare:
\[
a(e^{\lambda_1 x}u(x))'' + b(e^{\lambda_1 x}u(x))' + c(e^{\lambda_1 x}u(x)) = 0.
\]

Calcoliamo la prima derivata usando la regola del prodotto:
\[
(e^{\lambda_1 x}u(x))' = (e^{\lambda_1 x})' u(x) + e^{\lambda_1 x} u'(x) = \lambda_1 e^{\lambda_1 x} u(x) + e^{\lambda_1 x} u'(x).
\]

Calcoliamo la seconda derivata, applicando nuovamente la regola del prodotto:
\[
(e^{\lambda_1 x}u(x))'' = (\lambda_1 e^{\lambda_1 x} u(x) + e^{\lambda_1 x} u'(x))'
\]
\[
= (\lambda_1 e^{\lambda_1 x} u(x))' + (e^{\lambda_1 x} u'(x))'
\]
\[
= \lambda_1^2 e^{\lambda_1 x} u(x) + \lambda_1 e^{\lambda_1 x} u'(x) + \lambda_1 e^{\lambda_1 x} u'(x) + e^{\lambda_1 x} u''(x)
\]
\[
= \lambda_1^2 e^{\lambda_1 x} u(x) + 2\lambda_1 e^{\lambda_1 x} u'(x) + e^{\lambda_1 x} u''(x).
\]

Sostituiamo nell'equazione differenziale:
\[
a[\lambda_1^2 e^{\lambda_1 x} u(x) + 2\lambda_1 e^{\lambda_1 x} u'(x) + e^{\lambda_1 x} u''(x)] + b[\lambda_1 e^{\lambda_1 x} u(x) + e^{\lambda_1 x} u'(x)] + c[e^{\lambda_1 x}u(x)] = 0.
\]

Distribuiamo i coefficienti:
\[
a\lambda_1^2 e^{\lambda_1 x} u(x) + 2a\lambda_1 e^{\lambda_1 x} u'(x) + ae^{\lambda_1 x} u''(x) + b\lambda_1 e^{\lambda_1 x} u(x) + be^{\lambda_1 x} u'(x) + ce^{\lambda_1 x}u(x) = 0.
\]

Mettiamo in evidenza \(e^{\lambda_1 x}\) (che è sempre \(> 0\)):
\[
e^{\lambda_1 x}[(a\lambda_1^2 + b\lambda_1 + c)u(x) + au''(x) + (2a\lambda_1 + b)u'(x)] = 0.
\]

Dividendo per \(e^{\lambda_1 x}\):
\[
(a\lambda_1^2 + b\lambda_1 + c)u(x) + au''(x) + (2a\lambda_1 + b)u'(x) = 0.
\]

Ora, \(\lambda_1\) è soluzione dell'equazione caratteristica \(a\lambda^2 + b\lambda + c = 0\), quindi
\[
a\lambda_1^2 + b\lambda_1 + c = 0.
\]

Pertanto l'equazione si riduce a:
\[
au''(x) + (2a\lambda_1 + b)u'(x) = 0.
\]

Dividiamo per \(a\) (con \(a \neq 0\)):
\[
u''(x) + \left(2\lambda_1 + \frac{b}{a}\right)u'(x) = 0.
\]

Dall'equazione caratteristica \(a\lambda^2 + b\lambda + c = 0\), dividendo per \(a\):
\[
\lambda^2 + \frac{b}{a}\lambda + \frac{c}{a} = 0.
\]

Per le formule di Viète (o fattorizzando), sappiamo che se \(\lambda_1\) e \(\lambda_2\) sono le due radici:
\[
\lambda^2 + \frac{b}{a}\lambda + \frac{c}{a} = (\lambda - \lambda_1)(\lambda - \lambda_2).
\]

Espandendo il prodotto a destra:
\[
(\lambda - \lambda_1)(\lambda - \lambda_2) = \lambda^2 - \lambda_2\lambda - \lambda_1\lambda + \lambda_1\lambda_2 = \lambda^2 - (\lambda_1 + \lambda_2)\lambda + \lambda_1\lambda_2.
\]

Uguagliando i coefficienti:
\[
\lambda_1 + \lambda_2 = -\frac{b}{a}.
\]

Quindi:
\[
2\lambda_1 + \frac{b}{a} = 2\lambda_1 - (\lambda_1 + \lambda_2) = 2\lambda_1 - \lambda_1 - \lambda_2 = \lambda_1 - \lambda_2.
\]

L'equazione diventa:
\[
u''(x) + (\lambda_1 - \lambda_2)u'(x) = 0.
\]

Riscriviamo come:
\[
u''(x) - (\lambda_2 - \lambda_1)u'(x) = 0.
\]

Poniamo \(v(x) = u'(x)\). Allora \(v'(x) = u''(x)\), e l'equazione diventa:
\[
v'(x) - (\lambda_2 - \lambda_1)v(x) = 0.
\]

Questa è un'equazione differenziale del primo ordine a variabili separabili. Poniamo \(k = \lambda_2 - \lambda_1\):
\[
v'(x) - kv(x) = 0.
\]

Riscriviamo:
\[
v'(x) = kv(x).
\]

Separando le variabili (per \(v(x) \neq 0\)):
\[
\frac{dv}{v} = k\,dx.
\]

Integriamo entrambi i membri:
\[
\int \frac{dv}{v} = \int k\,dx
\]
\[
\ln|v| = kx + C_0
\]
\[
|v| = e^{kx + C_0} = e^{C_0} \cdot e^{kx}.
\]

Ponendo \(c = \pm e^{C_0}\):
\[
v(x) = c \cdot e^{kx} = c \cdot e^{(\lambda_2-\lambda_1)x}.
\]

Ricordando che \(v(x) = u'(x)\):
\[
u'(x) = c \cdot e^{(\lambda_2-\lambda_1)x}.
\]

Integriamo per trovare \(u(x)\):
\[
u(x) = \int c \cdot e^{(\lambda_2-\lambda_1)x}\,dx.
\]

Calcoliamo l'integrale (ricordando che \(\int e^{ax}dx = \frac{1}{a}e^{ax} + C\)):
\[
u(x) = c \cdot \frac{1}{\lambda_2-\lambda_1} e^{(\lambda_2-\lambda_1)x} + c_2.
\]

Poniamo \(c_1 = \frac{c}{\lambda_2-\lambda_1}\):
\[
u(x) = c_1 \cdot e^{(\lambda_2-\lambda_1)x} + c_2, \quad c_1, c_2 \in \mathbb{R}.
\]

Sostituiamo in \(z(x) = e^{\lambda_1 x}u(x)\):
\[
z(x) = e^{\lambda_1 x}[c_1 \cdot e^{(\lambda_2-\lambda_1)x} + c_2]
\]
\[
= c_1 \cdot e^{\lambda_1 x} \cdot e^{(\lambda_2-\lambda_1)x} + c_2 \cdot e^{\lambda_1 x}
\]
\[
= c_1 \cdot e^{\lambda_1 x + \lambda_2 x - \lambda_1 x} + c_2 \cdot e^{\lambda_1 x}
\]
\[
= c_1 \cdot e^{\lambda_2 x} + c_2 \cdot e^{\lambda_1 x}.
\]

Quindi ogni soluzione \(z(x)\) è una combinazione lineare di \(y_1(x) = e^{\lambda_1 x}\) e \(y_2(x) = e^{\lambda_2 x}\).
\vspace{1em}

\textbf{Caso 2: \(\Delta = 0\) (Radice reale doppia)}

In questo caso il discriminante è nullo:
\[
\Delta = b^2 - 4ac = 0,
\]
quindi l'equazione caratteristica ha una radice doppia:
\[
\lambda_1 = \lambda_2 = \lambda = -\frac{b}{2a}.
\]

Le soluzioni sono
\[
y_1(x) = e^{\lambda x}, \quad y_2(x) = xe^{\lambda x}.
\]

\textbf{{\color{thmcolor}Passo 1:} verifica dell'indipendenza lineare tramite Wronskiana}

Calcoliamo le derivate:
\[
y'_1(x) = \lambda e^{\lambda x},
\]
\[
y'_2(x) = (xe^{\lambda x})' = (x)' e^{\lambda x} + x(e^{\lambda x})' = e^{\lambda x} + x\lambda e^{\lambda x} = e^{\lambda x}(1 + \lambda x).
\]

Calcoliamo la Wronskiana:
\[
W(y_1(x), y_2(x)) = \begin{vmatrix} e^{\lambda x} & xe^{\lambda x} \\ \lambda e^{\lambda x} & e^{\lambda x}(1 + \lambda x) \end{vmatrix}.
\]

Calcoliamo il determinante:
\[
W(y_1(x), y_2(x)) = e^{\lambda x} \cdot e^{\lambda x}(1 + \lambda x) - xe^{\lambda x} \cdot \lambda e^{\lambda x}
\]
\[
= e^{2\lambda x}(1 + \lambda x) - \lambda x e^{2\lambda x}
\]
\[
= e^{2\lambda x} + \lambda x e^{2\lambda x} - \lambda x e^{2\lambda x}
\]
\[
= e^{2\lambda x}.
\]

Poiché \(e^{2\lambda x} > 0\) per ogni \(x\), concludiamo che
\[
W(y_1(x), y_2(x)) \neq 0.
\]

Quindi \(y_1(x)\) e \(y_2(x)\) sono linearmente indipendenti.

\textbf{{\color{thmcolor}Passo 2:} dimostrazione che ogni soluzione è combinazione lineare di \(y_1\) e \(y_2\)}

Sia \(z(x)\) una soluzione qualsiasi della forma
\[
z(x) = e^{\lambda x}u(x).
\]

Sostituiamo nell'equazione differenziale:
\[
a(e^{\lambda x}u(x))'' + b(e^{\lambda x}u(x))' + ce^{\lambda x}u(x) = 0.
\]

Calcoliamo la prima derivata:
\[
(e^{\lambda x}u(x))' = \lambda e^{\lambda x} u(x) + e^{\lambda x} u'(x).
\]

Calcoliamo la seconda derivata:
\[
(e^{\lambda x}u(x))'' = (\lambda e^{\lambda x} u(x) + e^{\lambda x} u'(x))'
\]
\[
= \lambda^2 e^{\lambda x} u(x) + \lambda e^{\lambda x} u'(x) + \lambda e^{\lambda x} u'(x) + e^{\lambda x} u''(x)
\]
\[
= \lambda^2 e^{\lambda x} u(x) + 2\lambda e^{\lambda x} u'(x) + e^{\lambda x} u''(x).
\]

Sostituiamo nell'equazione:
\[
a[\lambda^2 e^{\lambda x} u(x) + 2\lambda e^{\lambda x} u'(x) + e^{\lambda x} u''(x)] + b[\lambda e^{\lambda x} u(x) + e^{\lambda x} u'(x)] + ce^{\lambda x}u(x) = 0.
\]

Mettiamo in evidenza \(e^{\lambda x}\):
\[
e^{\lambda x}[(a\lambda^2 + b\lambda + c)u(x) + au''(x) + (2a\lambda + b)u'(x)] = 0.
\]

Poiché \(\lambda\) è soluzione dell'equazione caratteristica, \(a\lambda^2 + b\lambda + c = 0\), quindi:
\[
au''(x) + (2a\lambda + b)u'(x) = 0.
\]

Dividiamo per \(a\):
\[
u''(x) + \left(2\lambda + \frac{b}{a}\right)u'(x) = 0.
\]

Poiché \(\lambda = -\frac{b}{2a}\):
\[
2\lambda = 2 \cdot \left(-\frac{b}{2a}\right) = -\frac{b}{a}.
\]

Quindi:
\[
2\lambda + \frac{b}{a} = -\frac{b}{a} + \frac{b}{a} = 0.
\]

L'equazione diventa:
\[
u''(x) = 0.
\]

Poniamo \(v(x) = u'(x)\). Allora:
\[
v'(x) = 0.
\]

Integrando:
\[
v(x) = c, \quad c \in \mathbb{R}.
\]

Quindi \(u'(x) = c\). Integriamo nuovamente:
\[
u(x) = \int c\,dx = cx + c_2 = c_2 + c_1 x,
\]
dove abbiamo rinominato \(c = c_1\) e la costante di integrazione è \(c_2\).

Quindi:
\[
u(x) = c_1 + c_2 x, \quad c_1, c_2 \in \mathbb{R}.
\]

Sostituiamo in \(z(x) = e^{\lambda x}u(x)\):
\[
z(x) = e^{\lambda x}(c_1 + c_2 x) = c_1 e^{\lambda x} + c_2 x e^{\lambda x}.
\]

Quindi ogni soluzione \(z(x)\) è una combinazione lineare di \(y_1(x) = e^{\lambda x}\) e \(y_2(x) = xe^{\lambda x}\).
\vspace{1em}

\textbf{Caso 3: \(\Delta < 0\) (Due radici complesse coniugate)}

In questo caso il discriminante è negativo:
\[
\Delta = b^2 - 4ac < 0,
\]
quindi l'equazione caratteristica ha due radici complesse coniugate:
\[
\lambda_{1,2} = \alpha \pm i\beta,
\]
dove
\[
\alpha = -\frac{b}{2a}, \quad \beta = \frac{\sqrt{-\Delta}}{2a} = \frac{\sqrt{4ac-b^2}}{2a} \in \mathbb{R}.
\]

Le soluzioni complesse sono
\[
y_1(x) = e^{\lambda_1 x} = e^{(\alpha + i\beta)x}, \quad y_2(x) = e^{\lambda_2 x} = e^{(\alpha - i\beta)x}.
\]

\textbf{{\color{thmcolor}Passo 1:} verifica dell'indipendenza lineare tramite Wronskiana}

Calcoliamo le derivate:
\[
y'_1(x) = \lambda_1 e^{\lambda_1 x}, \quad y'_2(x) = \lambda_2 e^{\lambda_2 x}.
\]

Calcoliamo la Wronskiana:
\[
W(y_1(x), y_2(x)) = \begin{vmatrix} e^{\lambda_1 x} & e^{\lambda_2 x} \\ \lambda_1 e^{\lambda_1 x} & \lambda_2 e^{\lambda_2 x} \end{vmatrix}.
\]

Calcoliamo il determinante:
\[
W(y_1(x), y_2(x)) = e^{\lambda_1 x} \cdot \lambda_2 e^{\lambda_2 x} - e^{\lambda_2 x} \cdot \lambda_1 e^{\lambda_1 x}
\]
\[
= \lambda_2 e^{(\lambda_1+\lambda_2)x} - \lambda_1 e^{(\lambda_1+\lambda_2)x}
\]
\[
= (\lambda_2 - \lambda_1) e^{(\lambda_1+\lambda_2)x}.
\]

Calcoliamo \(\lambda_1 + \lambda_2\) e \(\lambda_2 - \lambda_1\):
\[
\lambda_1 + \lambda_2 = (\alpha + i\beta) + (\alpha - i\beta) = 2\alpha,
\]
\[
\lambda_2 - \lambda_1 = (\alpha - i\beta) - (\alpha + i\beta) = -2i\beta.
\]

Quindi:
\[
W(y_1(x), y_2(x)) = -2i\beta \cdot e^{2\alpha x} \neq 0,
\]
poiché \(\beta \neq 0\) (essendo \(\Delta < 0\)).

Quindi \(y_1(x)\) e \(y_2(x)\) sono linearmente indipendenti.

\textbf{{\color{thmcolor}Passo 2:} dimostrazione che ogni soluzione è combinazione lineare di \(y_1\) e \(y_2\)}

Sia \(z(x)\) una soluzione qualsiasi della forma
\[
z(x) = e^{\alpha x}u(x).
\]

Sostituiamo nell'equazione differenziale:
\[
a[e^{\alpha x}u(x)]'' + b[e^{\alpha x}u(x)]' + ce^{\alpha x}u(x) = 0.
\]

Calcoliamo la prima derivata:
\[
[e^{\alpha x}u(x)]' = \alpha e^{\alpha x} u(x) + e^{\alpha x} u'(x).
\]

Calcoliamo la seconda derivata:
\[
[e^{\alpha x}u(x)]'' = [\alpha e^{\alpha x} u(x) + e^{\alpha x} u'(x)]'
\]
\[
= \alpha^2 e^{\alpha x} u(x) + \alpha e^{\alpha x} u'(x) + \alpha e^{\alpha x} u'(x) + e^{\alpha x} u''(x)
\]
\[
= \alpha^2 e^{\alpha x} u(x) + 2\alpha e^{\alpha x} u'(x) + e^{\alpha x} u''(x).
\]

Sostituiamo nell'equazione:
\[
a[\alpha^2 e^{\alpha x} u(x) + 2\alpha e^{\alpha x} u'(x) + e^{\alpha x} u''(x)] + b[\alpha e^{\alpha x} u(x) + e^{\alpha x} u'(x)] + ce^{\alpha x}u(x) = 0.
\]

Mettiamo in evidenza \(e^{\alpha x}\):
\[
e^{\alpha x}[au''(x) + (2a\alpha + b)u'(x) + (a\alpha^2 + b\alpha + c)u(x)] = 0.
\]

Dividiamo per \(e^{\alpha x}\) e per \(a\):
\[
u''(x) + \left(2\alpha + \frac{b}{a}\right)u'(x) + \left(\alpha^2 + \frac{b\alpha}{a} + \frac{c}{a}\right)u(x) = 0.
\]

Sostituiamo \(\alpha = -\frac{b}{2a}\):
\[
2\alpha + \frac{b}{a} = 2 \cdot \left(-\frac{b}{2a}\right) + \frac{b}{a} = -\frac{b}{a} + \frac{b}{a} = 0.
\]

Calcoliamo il coefficiente di \(u(x)\):
\[
\alpha^2 + \frac{b\alpha}{a} + \frac{c}{a} = \left(-\frac{b}{2a}\right)^2 + \frac{b}{a} \cdot \left(-\frac{b}{2a}\right) + \frac{c}{a}
\]
\[
= \frac{b^2}{4a^2} - \frac{b^2}{2a^2} + \frac{c}{a}
\]
\[
= \frac{b^2 - 2b^2 + 4ac}{4a^2} = \frac{-b^2 + 4ac}{4a^2}.
\]

Poiché \(\Delta = b^2 - 4ac\):
\[
-b^2 + 4ac = -\Delta.
\]

Quindi:
\[
\alpha^2 + \frac{b\alpha}{a} + \frac{c}{a} = \frac{-\Delta}{4a^2}.
\]

Ricordando che \(\beta = \frac{\sqrt{-\Delta}}{2a}\), abbiamo:
\[
\beta^2 = \left(\frac{\sqrt{-\Delta}}{2a}\right)^2 = \frac{-\Delta}{4a^2}.
\]

L'equazione diventa:
\[
u''(x) + \beta^2 u(x) = 0.
\]

Questa è l'equazione dell'oscillatore armonico, la cui soluzione generale è:
\[
u(x) = c_1 \cos(\beta x) + c_2 \sin(\beta x), \quad c_1, c_2 \in \mathbb{R}.
\]

Sostituiamo in \(z(x) = e^{\alpha x}u(x)\):
\[
z(x) = e^{\alpha x}[c_1 \cos(\beta x) + c_2 \sin(\beta x)].
\]

Quindi l'integrale generale in forma reale è:
\[
z(x) = e^{\alpha x}[c_1 \cos(\beta x) + c_2 \sin(\beta x)].
\]

Questo può essere scritto come combinazione lineare di:
\[
y_1(x) = e^{\alpha x}\cos(\beta x), \quad y_2(x) = e^{\alpha x}\sin(\beta x).
\]

\hfill{\color{thmcolor}$\square$}

\subsection{Ricerca della soluzione particolare della EDO completa a coefficenti costanti}
\textbf{31. Quali sono i {\color{red}metodi per la ricerca della soluzione} particolare?}

Ci sono tre metodi per la ricerca della soluzione particolare della EDO non omogenea a coefficenti costanti di partenza in modo da verificare completamente le condizioni iniziali: ad occhio, con il metodo di variazione delle costanti e con il metodo di somiglianza.

\textbf{32. In cosa consiste {\color{red}Metodo di Somiglianza (o per Similitudine)}?}

Si analizza le fattezze del terimne noto per intuire le soluzioni particolari tramite una tabella  in cui è presente un riepilogo di tutti i casi dove si trova la soluzione per similitudine.\\
Data una EDO lineare di II ordine a coefficenti costanti $ay''(x)+by'(x)+cy(x)=f(x)$ è necessario distinguere i seguenti casi

\begin{table}[h]
\centering
\footnotesize
\begin{tabular}{|>{\raggedright\arraybackslash}p{2.2cm}|>{\raggedright\arraybackslash}p{2.8cm}|>{\raggedright\arraybackslash}p{5.5cm}|}
\hline
\rowcolor{tableheader}
\textcolor{white}{\textbf{Termine noto } $f(x)$} & 
\textcolor{white}{\textbf{Soluzione } $y_p(x)$} & 
\textcolor{white}{\textbf{Modifiche necessarie}} \\
\hline
$e^{\alpha x}$ & 
$Ae^{\alpha x}$ & 
• Moltiplicare per $x$ se $\alpha$ è radice semplice, moltiplicare per $x^2$ se $\alpha$ è radice doppia \\
\hline
$\cos(\beta x)$ o $\sin(\beta x)$ & 
$A\cos(\beta x) + B\sin(\beta x)$ & 
• Moltiplicare per $x$ se $i\beta$ è radice \\
\hline
$P_n(x)$ (polinomio grado $n$) & 
$Q_n(x)$ (polinomio grado $n$) & 
• Moltiplicare per $x$ se $0$ è radice semplice, moltiplicare per $x^2$ se $0$ è radice doppia \\
\hline
$e^{\alpha x}P_n(x)$ & 
$e^{\alpha x}Q_n(x)$ & 
• Applicare le regole come sopra per $\alpha$ \\
\hline
$e^{\alpha x}\cos(\beta x)$ o $e^{\alpha x}\sin(\beta x)$ & 
$e^{\alpha x}[A\cos(\beta x) + B\sin(\beta x)]$ & 
• Moltiplicare per $x$ se $\alpha \pm i\beta$ è radice \\
\hline
\end{tabular}
\end{table}
\newpage
\textbf{32. In cosa consiste {\color{red}Metodo di Variazione delle Costanti}?}

Il metodo delle variazioni delle costanti ha la soluzione particolare della EDO lineare di II ordine a coefficenti costanti della forma $\bar{y}(x) = c_1(x)y_1(x) + c_2(x)y_2(x)$ dove $x \in I = [a,b]$ e $c_1,_2 \in C^2(I)$ sono da determinare.

La formula che si applica per la soluzione particolare della EDO di I ordine si estende di una dimensione per l'aggiunta $c_2(x)y_2(x)$. Inoltre, imponendo che la funzione della forma $\bar{y}(x) = c_1(x)y_1(x) + c_2(x)y_2(x)$ sia soluzione particolare, sarà ottenuto un sistema nelle ipotesi $c_1'$ e $c_2'$ che sarà risolto tramite la regola di Cramer (teoria dei sistemi lineari).

\textbf{\color{thmcolor}DIMOSTRAZIONE}

Consideriamo l'equazione differenziale ordinaria (EDO) lineare del secondo ordine non omogenea a coefficienti costanti:
\[
a y''(x) + b y'(x) + c y(x) = f(x), \quad a \neq 0
\]

Vogliamo trovare una soluzione particolare $\bar{y}(x)$ di questa equazione. Quindi, supponiamo di conoscere due soluzioni linearmente indipendenti $y_1(x)$ e $y_2(x)$ dell'equazione omogenea associata e cerchiamo una soluzione particolare della forma:
\[
\bar{y}(x) = c_1(x) y_1(x) + c_2(x) y_2(x)
\]
dove $c_1(x)$ e $c_2(x)$ sono funzioni incognite da determinare (non più costanti come nell'omogenea).

\textbf{{\color{thmcolor}Passo 1}}: Deriviamo $\bar{y}(x)$ rispetto a $x$ applicando la regola del prodotto:
\[
\bar{y}'(x) = \frac{d}{dx}[c_1(x) y_1(x)] + \frac{d}{dx}[c_2(x) y_2(x)]
\]
\[
\bar{y}'(x) = c_1'(x) y_1(x) + c_1(x) y_1'(x) + c_2'(x) y_2(x) + c_2(x) y_2'(x)
\]

\textbf{{\color{thmcolor}Passo 2}}: Prima condizione (trucco di Lagrange)

Per semplificare i calcoli successivi, imponiamo la condizione:
\[
c_1'(x) y_1(x) + c_2'(x) y_2(x) = 0
\]

Questa è una scelta arbitraria che ci permette di eliminare alcuni termini.
La derivata prima diventa:
\[
\bar{y}'(x) = c_1(x) y_1'(x) + c_2(x) y_2'(x)
\]

\textbf{{\color{thmcolor}Passo 3}}: Calcolo della derivata seconda
Deriviamo nuovamente $\bar{y}'(x)$ applicando la regola del prodotto:
\[
\bar{y}''(x) = \frac{d}{dx}\left[c_1(x) y_1'(x) + c_2(x) y_2'(x)\right]
\]
\[
\bar{y}''(x) = \frac{d}{dx}[c_1(x) y_1'(x)] + \frac{d}{dx}[c_2(x) y_2'(x)]
\]
\[
\bar{y}''(x) = c_1'(x) y_1'(x) + c_1(x) y_1''(x) + c_2'(x) y_2'(x) + c_2(x) y_2''(x)
\]

\textbf{{\color{thmcolor}Passo 4}}: Sostituzione nell'EDO

Sostituiamo $\bar{y}(x)$, $\bar{y}'(x)$ e $\bar{y}''(x)$ nell'equazione differenziale originale:
\[
a y''(x) + b y'(x) + c y(x) = f(x)
\]

Sostituiamo:
\[
a\left[c_1'(x) y_1'(x) + c_1(x) y_1''(x) + c_2'(x) y_2'(x) + c_2(x) y_2''(x)\right]
\]
\[
+ b\left[c_1(x) y_1'(x) + c_2(x) y_2'(x)\right]
\]
\[
+ c\left[c_1(x) y_1(x) + c_2(x) y_2(x)\right] = f(x)
\]

\textbf{{\color{thmcolor}Passo 5}}:  Riordino dei termini

Distribuiamo i coefficienti $a$, $b$ e $c$:
\[
a c_1'(x) y_1'(x) + a c_1(x) y_1''(x) + a c_2'(x) y_2'(x) + a c_2(x) y_2''(x)
\]
\[
+ b c_1(x) y_1'(x) + b c_2(x) y_2'(x)
\]
\[
+ c c_1(x) y_1(x) + c c_2(x) y_2(x) = f(x)
\]

Raccogliamo i termini con $c_1(x)$ e con $c_2(x)$:
\[
c_1(x)\left[a y_1''(x) + b y_1'(x) + c y_1(x)\right]
\]
\[
+ c_2(x)\left[a y_2''(x) + b y_2'(x) + c y_2(x)\right]
\]
\[
+ a\left[c_1'(x) y_1'(x) + c_2'(x) y_2'(x)\right] = f(x)
\]

\textbf{{\color{thmcolor}Passo 6}}:  Semplificazione

Poiché $y_1(x)$ e $y_2(x)$ sono soluzioni dell'equazione omogenea, abbiamo:
\[
a y_1''(x) + b y_1'(x) + c y_1(x) = 0
\]
\[
a y_2''(x) + b y_2'(x) + c y_2(x) = 0
\]

Quindi i primi due termini si annullano:
\[
c_1(x) \cdot 0 + c_2(x) \cdot 0 + a\left[c_1'(x) y_1'(x) + c_2'(x) y_2'(x)\right] = f(x)
\]

L'equazione si riduce a:
\[
a\left[c_1'(x) y_1'(x) + c_2'(x) y_2'(x)\right] = f(x)
\]

Dividendo entrambi i membri per $a \neq 0$:
\[
c_1'(x) y_1'(x) + c_2'(x) y_2'(x) = \frac{f(x)}{a}
\]

\textbf{{\color{thmcolor}Passo 7}}:  Sistema di equazioni

Otteniamo il sistema lineare $2 \times 2$ nelle incognite $c_1'(x)$ e $c_2'(x)$:
\[
\begin{cases}
c_1'(x) y_1(x) + c_2'(x) y_2(x) = 0 \\[0.3em]
c_1'(x) y_1'(x) + c_2'(x) y_2'(x) = \dfrac{f(x)}{a}
\end{cases}
\]

\textbf{{\color{thmcolor}Passo 8}}:  Verifica dell'esistenza e unicità della soluzione

La matrice dei coefficienti del sistema è:
\[
A = \begin{pmatrix}
y_1(x) & y_2(x) \\
y_1'(x) & y_2'(x)
\end{pmatrix}
\]

Il determinante di questa matrice è:
\[
\det(A) = \begin{vmatrix}
y_1(x) & y_2(x) \\
y_1'(x) & y_2'(x)
\end{vmatrix} = y_1(x) y_2'(x) - y_2(x) y_1'(x) = W(x) \neq 0
\]

Poiché $W(x) \neq 0$ (le soluzioni $y_1$ e $y_2$ sono linearmente indipendenti), il sistema ammette un'unica soluzione per le incognite $c_1'(x)$ e $c_2'(x)$.

\textbf{{\color{thmcolor}Passo 9}}:  Risoluzione del sistema con la regola di Cramer

Applichiamo la regola di Cramer per trovare $c_1'(x)$ e $c_2'(x)$.

\newpage
\textbf{Per $c_1'(x)$:}

Secondo la regola di Cramer, $c_1'(x)$ si ottiene sostituendo la prima colonna della matrice dei coefficienti con il vettore dei termini noti e dividendo per il determinante $W(x)$:
\[
c_1'(x) = \frac{\begin{vmatrix}
0 & y_2(x) \\[0.3em]
\dfrac{f(x)}{a} & y_2'(x)
\end{vmatrix}}{W(x)}
\]

Calcoliamo il determinante al numeratore:
\[
\begin{vmatrix}
0 & y_2(x) \\[0.3em]
\dfrac{f(x)}{a} & y_2'(x)
\end{vmatrix} = 0 \cdot y_2'(x) - y_2(x) \cdot \frac{f(x)}{a} = -\frac{y_2(x) f(x)}{a}
\]

Quindi:
\[
c_1'(x) = \frac{-\dfrac{y_2(x) f(x)}{a}}{W(x)} = -\frac{y_2(x) f(x)}{a \cdot W(x)}
\]

\textbf{Per $c_2'(x)$:}

Secondo la regola di Cramer, $c_2'(x)$ si ottiene sostituendo la seconda colonna della matrice dei coefficienti con il vettore dei termini noti e dividendo per il determinante $W(x)$:
\[
c_2'(x) = \frac{\begin{vmatrix}
y_1(x) & 0 \\[0.3em]
y_1'(x) & \dfrac{f(x)}{a}
\end{vmatrix}}{W(x)}
\]

Calcoliamo il determinante al numeratore:
\[
\begin{vmatrix}
y_1(x) & 0 \\[0.3em]
y_1'(x) & \dfrac{f(x)}{a}
\end{vmatrix} = y_1(x) \cdot \frac{f(x)}{a} - 0 \cdot y_1'(x) = \frac{y_1(x) f(x)}{a}
\]

Quindi:
\[
c_2'(x) = \frac{\dfrac{y_1(x) f(x)}{a}}{W(x)} = \frac{y_1(x) f(x)}{a \cdot W(x)}
\]

\textbf{{\color{thmcolor}Passo 10}}: Integrazione

Per trovare $c_1(x)$ e $c_2(x)$, integriamo $c_1'(x)$ e $c_2'(x)$ rispetto a $x$:
\[
c_1(x) = \int c_1'(x) \, dx = \int \left(-\frac{y_2(x) f(x)}{a \cdot W(x)}\right) dx = -\int \frac{y_2(x) f(x)}{a \cdot W(x)} \, dx
\]
\[
c_2(x) = \int c_2'(x) \, dx = \int \frac{y_1(x) f(x)}{a \cdot W(x)} \, dx
\]

\textbf{Nota importante:} Non aggiungiamo costanti di integrazione perché stiamo cercando una soluzione particolare della EDO non omogenea, non la soluzione generale. Le costanti arbitrarie saranno presenti nella soluzione dell'omogenea.

\textbf{{\color{thmcolor}Passo 11}}:  Soluzione particolare

La soluzione particolare dell'EDO non omogenea è:
\[
\bar{y}(x) = c_1(x) y_1(x) + c_2(x) y_2(x)
\]

Esplicitamente:
\[
\bar{y}(x) = \left[-\int \frac{y_2(x) f(x)}{a \cdot W(x)} \, dx\right] y_1(x) + \left[\int \frac{y_1(x) f(x)}{a \cdot W(x)} \, dx\right] y_2(x)
\]

\hfill{\color{thmcolor}$\square$}

\subsubsection{Problema di Cauchy}
\textbf{33. Come si formula {\color{red}un problema di Cauchy per un'EDO del secondo ordine}?}


Per una EDO lineare del II ordine della forma $ay''(x)+by'(x)+cy(x)=f(x)$ con $a,b,c$ costanti, $a \neq 0$ e $f(x)$ è continua su un intervallo $I$ dove è presente $x_0$
\[
\begin{cases}
        ay''(x)+by'(x)+cy(x) &=f(x) \\ 
        y(x_0) &= y_0 \\ 
        y'(x_0) &= y_1
    \end{cases}
\]  
\textbf{Come si risolve?}
\begin{enumerate}
    \item Trova l'integrale generale dell'equazione omogenea $z(x)= c_1y_1(x)+c_2y_2(x)$
    \item Trova una soluzione particolare $\bar{y}(x)$ usando uno dei metodi descritti
    \item Unendo tutto si ottiene $y(x) = z(x) + \bar{y}(x)= c_1y_1(x)+c_2y_2(x)+\bar{y}(x)$
    \item Bisogna trovare le condizioni iniziali per determinare $c_1$ e $c_2$:\\
    $y(x_0) = c_1y_1(x_0)+c_2y_2(x_0)+y_p(x_0)= y_0$\\
    $y'(x_0) = c_1y'_1(x_0)+c_2y'_2(x_0)+y'_p(x_0)= y_1$
    \item Si risolve il sistema 2x2 con le incognite $c_1$ e $c_2$
\end{enumerate}





\end{document}
